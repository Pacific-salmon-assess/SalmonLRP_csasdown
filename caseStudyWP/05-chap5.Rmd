---
output:
  pdf_document: default
  html_document: default
---
# CASE STUDY 3: INSIDE SOUTH COAST CHUM - NON-FRASER

<!-- # Add a comment in colour: *\textcolor{cyan}{LW: some text}* -->

<!-- Initials: my comment -->

## CONTEXT

The 'Inside South Coast Chum - Non-Fraser' (ISC-NF Chum) SMU includes seven CUs of chum salmon (*Oncorhynchus keta*) from rivers that drain into Johnstone Strait and the Salish Sea along the mainland of British Columbia and the east coast of Vancouver Island (Figure \@ref(fig:chum-map); @holtby_conservation_2007). This area includes deep fjords, glaciers, large rivers, and small coastal streams. Chum salmon CUs spawning in the Fraser River watershed are not included in this SMU. They have been categorized as a separate 'Inside South Coast Chum - Fraser' SMU. While these two SMUs have substantial overlap in ocean fisheries, they have been separated into two SMUs based on differences in terminal fishery impacts and freshwater habitats.

The ISC Chum SMU is considered data-limited. While escapement series are available for many streams starting in 1953, several series are incomplete and require infilling assumptions  (i.e., not all streams counted each year, some CUs have no counts in some years). In addition, run reconstructions of recruitment are uncertain, making the development of benchmarks based on spawner and recruit data problematic. There are also no data on marine survival (although there are some scale/growth data in @debertin_marine_2017).
As a result, benchmarks are calculated as a percentile of the historical CU-level spawner abundance time series (percentile benchmarks) instead of spawner recruit relationships. Previous work on developing WSP benchmarks for Inner South Coast Chum has shown that percentile benchmarks can be comparable to those based on stock-recruit relationships when productivity is relatively high and harvest is relatively low (@holt_evaluating_2018). In other cases, percentile benchmarks may be inappropriate because they do not account for shifting baselines (@holt_evaluating_2018).

<!-- K.H. comment: Is it possible to calculate a couple summary stats that demonstrate the magnitude of infilling?  If so, this could be worked into the above paragraph.  For example, how many stream-year combinations are missing, and in need of infilling? --->

We chose ISC-NF Chum SMU as a case study because we were interested in exploring LRP options for a data-limited SMU. Additional unique characteristics of this SMU include high contrast in abundance among CUs and relatively low correlation in abundance among CUs over time. The SMU covers a large area with many diverse watersheds, flow regimes, and ocean entry locations.

```{r chum-map, fig.cap="The seven Conservation Units that make up the Inside South Coast Chum Stock Management Unit (not including Lower Fraser and Fraser Canyon Conservation Units).", warning=FALSE, echo=FALSE, fig.align="center"}
knitr::include_graphics("figure/chum-map.png")
```

## DATA

We used the same data used in @holt_evaluating_2018, but updated with escapement data to 2018. @van_will_inner_2014 provides more details on the data sources, infilling procedures and run reconstruction, which were reproduced for this study and described below. We did not include the Lower Fraser or Fraser Canyon chum CUs. 

<!-- K.H. comment: As discussed, much of this detail has been moved to a stand-alone Appendix on Chum data sources / data treatment (currently appendix A, but this will change).  This "DATA" section can just be a paragraph the lists the main data inputs and then references the Appendix.

-->


## METHODS

Data and methods are available at: https://github.com/Pacific-salmon-assess/SalmonLRP_RetroEval.


<!-- K.H. comment: Have we checked with Pieter on whether he is ok with Chum data being publically accessible on github?  We should make sure we have approval from him via email.
-->


### CU Status Estimation for ISC-NF Chum


<!--K.H. comment:

I suggest flipping this section around so that the general outline is something like:
# ==============================================================================
- Describe abundance-based benchmarks based on percentiles that have previously been used for SC Chum (cite Holt et al. 2018).  Note that Holt et al. calculated SR-based benchmarks for some SC Chum stocks, but did not recommend them due to uncertainty in spawner recruit data.
- Note that several other benchmarks would also be considered as part of an integrated status assessment (trends, distribution of abundance), but that an integrated status assessment has not yet been developed for SC chum.
- For this case study, we consider two approaches for characterizing CU status: (i) percentile benchmarks and (ii) multi-dimensional status assessment (State of the Salmon program; still in development).  [Note: as discussed, I think it makes sense to take out Sgen as a benchmark to evaluate; however, in light of your note about the SR data still being used for assessing patterns in productivity, we should flag this as something to discuss more with Carrie]
- Note assumptions of constant productivity for these methods, and include 1-2 sentences to highlight that this may be concern for SC chum (cite a few papers on competition, changes in marine environment, etc, as relevant).
# ===========================================================================


Based on @government_of_canada_fishery_2009:
"When developing reference points efforts should be made to take into consideration the range of factors which may affect the productivity of the stock including changes in ocean conditions, where information is available."

Range of factors which may affect the productivity of Inside South Coast Chum:

- Ocean conditions:
  - Competition / Biomass of North American pink, sockeye, and chum salmon @debertin_marine_2017, @litz_competition_2021
  - Pacific Decadal Oscillation (PDO) (both positive and negative depending on what time period examined) @litz_competition_2021
  - North Pacific Gyre Oscillation (NPGO) (positive relationship with growth), interaction between PDO and NPGO @debertin_marine_2017
  - Early marine entry temperature (inlets)
  - Timing of spring bloom
  - Ocean ecology during time at sea (zooplankton, forage fish available) - dependent on ocean temperature @cheng_upper_2021
- Interacting / carry-over / complex effects:
  - winter incubation temperatures -> earlier emergence -> potential mismatch with spring bloom Wilson 2021 thesis (chum outmigration getting earlier)
  - ocean conditions -> female adult size -> egg burial depth * scour flood frequency/intensity (climate change) * land cover (exacerbating factors of floods) -> lower egg to adult survival
  - female adult size -> egg size -> lower condition at estuary entry -> lower early marine survival
- Habitat loss
  - estuary loss (human, climate change)
  - change in quality of spawning habitat (change in sediment regime, possibly from forestry, landslides, potential climate change induced/exacerbated).
- Fishing mortality (Alaska, BC)
- Predation
- Depensation at low spawner abundance 
- Negative impacts of hatchery fish

From @holt_evaluating_2018: "Status assessments under the WSP integrate numerous metrics, including those on abundances, trends in abundance, and spatial distribution (Holt et al. 2009). Benchmarks on abundances (percentile or stock-recruitment based) are only one component of an integrated assessment of status that includes numerous other metrics (Grant and Pestal 2013; DFO 2015; DFO 2016)."

Based on the recommendations in *Guidelines Working Paper*, we used benchmarks at the scale of Conservation Units to evaluate Limit Reference Points for Inside South Coast Chum. We compared two different benchmarks at the CU level: $S_{gen}$ (based on Ricker parameters) and percentiles based on historical abundance. We used these benchmarks for this case study because previous work evaluated whether abundance-based benchmarks were appropriate for data-limited Chum populations (@holt_evaluating_2018). 

--> 




**Abundance Relative to Percentile Benchmark**

*\textcolor{cyan}{LW: some of this is probably too much detail, but I am keeping track of my thoughts here for now}*


<!-- K.H. comment: I agree that this section should be shortened.  I suggest describing the method and citing a couple papers that have previously used it, and then including a couple sentences that highlight major assumptions that may not be appropriate. A more detailed discussion of these caveats / assumption can then be added to the Chapter 5 discussion -->

Estimating benchmarks for salmon populations without a long time series and without data on prodcutivity (only escapement, no recruits/smolt production) is challenging. Previous evaluations of Inside South Coast chum population status used a 25% benchmark (@hilborn_british_2012). This was based on previous work by the Alaska Department of Fish and Game that defined four tiers of populations based on conrast in spawner abunances, harvest rate, and precision of escapement data (@bue_escapement_2001, @otis_escapement_2004). The goal of these tiers was to choose a Sustainable Escapement Goal (an upper and lower percentile) to use as a goal for escapement to "represents a proxy for maintaining escapements within a range that encompasses $S_{MSY}$" (@clark_evaluation_2014). These SEGs were calculated for each major river/system and are still done that way now in Alaska (@mckinley_review_2020). Tier 1 of this method was for high escapement contrast (greater than 8) and at least moderate harvest rate, with a SEG of 25th to 75th percentiles. @bue_escapement_2001 assessed this method on "11 selected stocks. The specific stocks examined were 2 sockeye salmon and 2 Chinook salmon stocks from Upper Cook Inlet, and 7 sockeye salmon stocks from Bristol Bay (in @clark_evaluation_2014). @clark_evaluation_2014 tested the suitability of this 4 tier percentile approach by applying a theoretical, simulation, and meta-analysis on "76 stock-recruitment data sets from throughout Alaska using a standard linear regression approach. These data included historical stock-recruitment observations for 7 pink salmon, 7 coho salmon, 43 sockeye salmon, 6 chum salmon stocks, and 13 Chinook salmon stocks". They recommended a revised 3 tier system, which changed the Tier 1 lower perecntile to 20%. @hilborn_british_2012 adopted the previous 25% lower limit of SEG as a benchmark for evaluating the status of Inside South Coast Chum in BC for the purpose of certification with the Marine Stewardship Council (@hilborn_british_2012), despite it lack of testing for populations of chum salmon in British Columbia. Further, SEGs were and still are applied to individual rivers in Alaska, compared to the application of this method to entire CUs, which, for ISC Chum, which has 296 streams among the seven CUs, with 126 in Strait of Georgia alone. By aggregating spawners and recruits across many rivers before estimating benchmarks of percentile or stock-recruit parameters, the following problems may arise:

- Error in fitting stock-recruit curves because it is at aggregate level instead of by river
- Sum of $S_{gen}$ calculated for individual rivers may not equal $S_{gen}$ calculated using aggregated spawner and recruit data
- Non-stationarity of productivity in individual systems may be hidden by aggregating spawners and recruits
- Spawner abundance at CU level may not be a good predictor of status of individual rivers compared to SEGs at the river scale (similar to the problem of SMU aggregate LRP logistic regression), depending on the contrast in size between rivers and the correlation (or lack) in escapement and/or productivity

The suitability of the percentile method was evaluated for chum populations in BC by @holt_evaluating_2018, who tested how well percentile benchmarks matched benchmarks from stock-recruit parameters for Inside South Coast Chum, using retrospective and simulation analyses. Among other things, they tested how well a 25% percentile benchmark (and higher values up to 50%) compared to estimates of $S_{gen}$ for these CUs. They found that:

- Percentile benchmarks (even 50%) under moderate-high harvest rates and low-moderate productivity tended to underestimate 'true' $S_{gen}$ values, which would lead to optimistic and incorrect status assessments. More work on alternatives to percentile benchmarks are needed in this case
- Time series bias tends to under-estimate $S_{gen}$ 
 
 
@holt_evaluating_2018 recommended different percentiles to be used based on Ricker $\alpha$ and average harvest rate (table \@ref(tab:holt-tab6)).

```{r holt-tab6, fig.cap="Selected percentile-based lower and upper benchmarks identified to be similar or higher in value than stock-recruitment based benchmarks under the WSP, along gradients in productivity (recruits/spawner) and average harvest rates. * denotes the low-productivity scenario where lower and upper Ricker-based benchmarks are very close to one another, resulting in lower and upper percentile-based benchmarks that are the same. From @holt_evaluating_2018.", warning=FALSE, echo=FALSE, fig.align="center"}
knitr::include_graphics("figure/holt_et_al_2018_table6.png")
```

- Productivity (Ricker $\alpha$) between 2.5-4, harvest rate 20-40%: 25^th^ lower benchmark (Georgia Strait, Howe Sound Burrard Inlet)
- Productivity ($\alpha$) between 1.5-2.5 and: 
  - harvest rate 0-20%: 50^th^ lower benchmark (Loughborough, Northeast Vancouver Island, Upper Knight)
  - harvest rate 20-40%: further evaluation required, percentiles not recommended (Bute Inlet)
- Productivity ($\alpha$) <1.5: no category in @holt_evaluating_2018, assume further evaluation required, percentiles not recommended (Southern Coastal Streams)

We used 25% of spawner abundance as a benchmark for Georgia Strait and Howe Sound Burrard Inlet, 50% for Loughborough, Northeast Vancouver Island, Upper Knight, and the multidimensional approach for Bute Inlet and Southern Coastal Streams.*\textcolor{cyan}{LW: may need to revise the last three based on multi-dimensional methods}*

Caveats with benchmarks based on percentile of abundance: 

- Shifting baselines within period of data (e.g., Southern Coastal Streams)
- Shifting baselines (higher baseline before period of data)
- Assumes productivity (recruits/spawner) stationary
- record only starts with data 
- Accounting for fishing mortality? percentile of recruits vs. escapement



**Multi-dimensional CU Status Assessment**





<!--
K.Holt: I have commented out this section (Benchmark based on stock-recruit relationships - $S_{gen}) for now as I do not think we are using Sgen to calculate LRPs.If we do not evaluate LRPs based on Sgen, but still need to describe SR modelling for Sgen as it is used to estimate productivity for the percentile methods, we may wish to describe the SR modelling and results in an appendix?  In this case, we would not however need to estimate Smsy or Sgen.  Just ricker pars.



**Benchmark based on stock-recruit relationships - $S_{gen}$**

For Inside South Coast chum, there are no reliable data on marine survival for wild fish, and no proxies based on coded wire tag or age at return of hatchery chum in this SMU. This meant that the Ricker model used to estimate the spawner-recruit relationship did not account for variation in marine survival (compared to Interior Fraser Coho). 

The basic Ricker equation uses spawners $S$, productivity $\alpha$, and the strength of density dependence $\beta$ to predict recruits $R$ (Equation \@ref(eq:ricker)). Note that recruits includes returning adult spawners and adults caught in fisheries on their migration to spawn. We used the log-transformed Ricker equation so that the residuals/error would be normally distributed *\textcolor{cyan}{LW: is this correct about the residuals/error?}* (Equation \@ref(eq:logricker)). 

\begin{equation}
    R = \alpha S e^{-\beta S} 
    (\#eq:ricker)
\end{equation}

\begin{equation}
  log(\hat{R}) = log(\alpha_i) + log(S) - S \beta_i 
  (\#eq:logricker)
\end{equation}
  
We estimated the predicted recruits $\hat{R}$ from spawners $S$, productivity $\alpha$, and the strength of density dependence $\beta$ for each stock $i$ (Equation \@ref(eq:logricker)).  The natural log of observed recruits per spawner $log(\frac{R}{S})$ were assumed to be drawn from a normal distribution (normal error) with mean $log(\frac{\hat{R}}{S})$ and standard deviation $\sigma_i$ (Equation \@ref(eq:likelihood-recruits)).

\begin{equation}
    log(\frac{R}{S}) \sim Normal( log(\frac{\hat{R}}{S}) , \sigma_i)
    (\#eq:likelihood-recruits)
\end{equation}

$S_{MSY}$ *\textcolor{cyan}{LW:$S_{MSY}$ or $SMSY$?)* was calculated using Lambert's W function @scheuerell_explicit_2016 (Equation \@ref(eq:SMSY))

\begin{equation}
    S_{MSY} = \frac { 1 - Lambert_W(e ^ {1-log(\alpha)})} {\beta}
    (\#eq:SMSY)
\end{equation}

$S_{gen}$ was estimated from $S_{MSY}$ by assuming that the difference between the $\hat{S}_{MSY}$ (estimated from $\alpha$, $\beta$, and $S_{gen}$) and the $S_{MSY}$ calculated using Lambert's W function was normally distributed with mean 0 and standard deviation $\sigma_{S_{gen}}$ (Equations \@ref(eq:Sgen), \@ref(eq:likelihood-Sgen)).

\begin{equation}
    log(\hat{S}_{MSY}) = log(\alpha) + log(S_{gen}) - \beta S_{gen}
    (\#eq:Sgen)
\end{equation}

\begin{equation}
    \hat{S}_{MSY} - S_{MSY} \sim Normal( 0, \sigma_{S_{gen}})
    (\#eq:likelihood-Sgen)
\end{equation}


We used R (@r_core_team_r_2021) and the Template Model Builder *TMB* package (@kristensen_tmb_2016) to fit Ricker models and logistic regressions of aggregate abundance . 

Caveats with benchmarks based on $S_{gen}$ or stock-recruit parameters:

- Ignores variability in actual recruits/spawner ($S_{gen}$ is based on mean $\alpha$ value). This can be problematic if there are large residuals (especially negative) in the stock-recruit curve at low spawner abundance. For example, if 20% of the time (based on record of recruits/spawner), $S_{gen}$ spawners actually had recruits/spawner less than 1. Then you set up a potential tail-spin to low abundance, depending on the frequency of these low recruitment cohorts at low abundance.
- Because they are set at the CU level (high level in terms of stock-recruit relationship, not at the scale of stream-level density-dependence or ocean-level density dependence including overlapping species (e.g., individual stream, Pacific ocean)), they may not explicitly model density dependence at scales where it is probably occurring.
- Assumes productivity and density-dependence are constant
- $\alpha$ and $\beta$ are correlated: sensitive to each other, especially when fit is not good, this is problematic, especially since $S_{MSY}$ and $S_{gen}$ depend on both $\alpha$ and $\beta$
- $MSY$ and its derivatives, e.g., $S_{MSY}$, $S_{gen}$ are not based on COSEWIC risk of extinction metrics such as percent decreases in spawner abundance
- Doesn't account for depensation
- The only dependent variables used are recruits and spawners, no other variables that are possibly linked to productivity


--> 

### LRP Estimation for ISC-NF Chum


We evaluated six different combinations of data and LRP estimation (table \@ref(tab:LRP-scenarios)). 

```{r LRP-scenarios, echo=FALSE}
d <- read.csv("data/2021-07-23 scenarios compare CU status methods.csv")
csasdown::csas_table(d[1:6,1:8], 
   align = rep("c", 8),
   caption = #ifelse(french,
                   #"French goes here",
                   "Scenarios using different LRP estimation methods and subsets of the data.")
            #)
```

**Proportion of CUs > percentiles**


**Proportion of CUs with multi-dimensional status > benchmark**



**Logistic Regression LRPs**

We evaluated two methods for developing LRPs based on aggregate abundance for Inside South Coast Chum.

<!-- K.Holt comment: I have copy and pasted the following text to the guidance working paper. This paper will include a section about when aggregate-abundance based benchmarks may be considered: 
The goal of these methods was to explore whether the status of component CUs could be predicted well by the aggregate abundance of the whole SMU. The motivation behind this approach is that many SMUs are not monitored at the CU level. If the aggregate abundance of the SMU could predict the status of component CUs, then an LRP that is measured in aggregate SMU abundance could be reliably used. 

--> 

These methods used 5 CUs with over 50 years of data (Bute Inlet and Upper Knight both had CU-level infilling in recent years and thus were left out of this analysis). Both approaches attempted to estimate LRPs by fitting logistic regression models to historically observed data. The two methods differ in what method was used to assess CU-level benchmarks.

The first approach uses $S_{gen}$ as a benchmark, which is derived from the parameters of the Ricker model of recruitment.

The second approach uses a percentile of past spawner abundance as a benchmark. 

These methods were applied retrospectively. For a series of years up to the most recent, the benchmarks and logistic regressions were calculated with all years up to that year. This was done for all successive years to see how the LRP (and benchmarks, and underlying stock-recruit parameters) would have changed over time as more data was collected.

Due to poor logistic model fits using the entire 19xx - 2018 time series for both Sgen and percentile benchmarks, we did not conduct retrospective analyses for this SMU. The underlying data characteristics that lead to poor logsitic model fits are highlighted in the results section below.






<!-- K.Holt: I have moved the more generic methods text that was here up to the multi-dimensional section of Chapter 2 of the case study paper.  This section in the chum chpater should focus specifically on the methods used to apply the multi-dimensional framework to chum. 

#### USING MULTIDIMENSIONAL APPROACH TO ASSESS CU STATUS

-->

<!-- K.Holt: I have commented out the following sections bc I don't thing they warrant their own headers. Also - I don't think we'll show Binomial regression results at all in this paper, so I don't think we need the "regression forms" header. 


### Regression forms

Regression forms are described in [Chapter 2][LOGISTIC REGRESSION LRPS]

We tested Bernoulli and Binomial regression forms. Because LRPs based on Binomial regressions are highly sensitive to which proportion of CUs above their benhcmark is chosed (e.g., 0.8, 0.9, 0.95, 0.99), we chose to proceed with the Bernoulli regression, which does not have this issue.

### PROJECTED LRPS (TBD)



--> 

## RESULTS

### Retrospective analysis of CU benchmarks based on $S_{gen}$ and percentiles

In the retrospective analysis, the estimates of $\alpha$, $\beta$, and $S_{gen}$ changed as pregressively more years of data were included (Figures \@ref(fig:chum-a-b-SMSY-Sgen-retro)). Note that these are not estimates based on a model that accounts for time-varying paramters. Rather, the estimates of $\alpha$, $\beta$, and $S_{gen}$ in a given year come from fitting a Ricker model to spawners and recruits for all years up to and including that year, for each CU. Each subsequent year includes another year of data. Thus, as more data is included, the estimates of $\alpha$, $\beta$, and $S_{gen}$ may change. These results should be interpreted with caution due to the large residuals in observed vs. predicted recruits. Since $\alpha$ and $\beta$ are correlated, the meaning of any trends in one parameter should be interpreted with the other parameter in mind, escpecially when model fits have large residuals. Similarly, since $\alpha$ and  $\beta$ determine $S_{MSY}$ and $S_{gen}$, changes in these derived parameters can be challenging to interpret and can be due to changes in $\alpha$,  $\beta$, and their relative values.

```{r chum-a-b-SMSY-Sgen-retro, fig.cap="Retrospective estimates of $\\alpha$, $\\beta$, $S_{gen}$ (black line with gray confidence intervals) and $S_{MSY}$ (blue line) for five CUs in the Inside South Coast Chum SMU. Note y axis is identical across CUs for $\\alpha$ but varies for other parameters.", warning=FALSE, echo=FALSE, fig.align="center"}
download.file('https://github.com/Pacific-salmon-assess/SalmonLRP_RetroEval/raw/master/SCChumStudy/Figures/fig_a_b_SMSY_Sgen_retro.png', './figure/chum-a-b-SMSY-Sgen-retro.png',  mode="wb")
knitr::include_graphics(here::here('figure/chum-a-b-SMSY-Sgen-retro.png'))
```

Retrospective estimates of $\alpha$ and $\beta$ for Southern Coastal Streams show declines over time. $S_{MSY}$ and $S_{gen}$ increase sharply in the first few years due to large decreases in $\alpha$ and $\beta$. $S_{MSY}$ then decreases over time, while $S_{gen}$ stays relatively stable. This is because as $\alpha$ decreases below ~2.5, $S_{gen}$ decreases, but as $\beta$ decreases, $S_{gen}$ decreases, so that a simultaneous decrease in $\alpha$ and $\beta$ can cancel out. However, the lower alpha is below 2.5, the less influence $\beta$ has on $S_{gen}$. *\textcolor{cyan}{This is from my work on sensitivity of Sgen and SMSY to alpha and beta. Not sure if we can include here}*

Increasing $S_{gen}$ for North East Vancouver Island is mainly due to an increase in $\alpha$ from <1.5 to >2 and then a decrease in $\beta$. 

$\alpha$ for Loughborough showed modest decreases over time, and $S_{gen}$ was fairly stable. 

The Georgia Strait CU shows evidence of increasing $\alpha$, and its $S_{gen}$ estimate was fairly stable. 

Howe Sound-Burrard Inlet $S_{gen}$ was fairly stable, and then increased due to  decreases in $\alpha$ and $\beta$. 


```{r chum-perc-retro, fig.cap="Escapement with 25th and 50th percentile benchmarks shown by gray and black dotted lines, respectively. Benchmarks are calculated using escapements up to the given year. Values following the CU names indicate the appropriate percentile benchmark. Green and red points indicate status above or below benchmark, respectively. Transparent points are years with CU-level infilling.", warning=FALSE, echo=FALSE, fig.align="center"}
download.file('https://github.com/Pacific-salmon-assess/SalmonLRP_RetroEval/raw/master/SCChumStudy/Figures/fig_perc_benchmarks_annual_retro.png', './figure/chum-perc-retro.png', mode="wb")
knitr::include_graphics(here::here('figure/chum-perc-retro.png'))
```

Four CUs were used to estimate percentile benchmarks and to estimate LRPs based on aggregate abundance and logistic regression. As more years of data were inlcuded, percentile benchmarks increased over time for Georgia Strait (especially the 50^th^ percentile) and had modest increases for Howe Sound-Burrard Inlet (Figure \@ref(fig:chum-perc-retro)). Percentile benchmarks decreased by a small amount for Loughborough and North East Vancouver Island. 

Percentile approaches were not used for the other three CUs for the purpose of the logistic regression of aggregate abundace because they were not appropriate based on productivity and harvest rates (see @holt_evaluating_2018 Table 6), CU-level infilling, or both (although they are shown in Figure \@ref(fig:chum-perc-retro)). Among these three CUs, Southern Coastal Streams and Upper Knight show evidence of shifting baselines if percentile approaches are used. 

### CU status based on decision tree

(don't get caught up with percentile / alpha constraint)

Using this method, X out of Y CUs would be above their lower benchmark (amber or green zone) and X would be below . 

(If we get the code, and do retrospective analysis, ... )

### LRPs based on SMU aggregate abundance and logistic models

The logistic models predicting whether all CUs were above their benchmark based on aggregate abundance fit the data poorly (Figures \@ref(fig:chum-logistic-sgen), \@ref(fig:chum-logistic-perc)). In both cases, the sum of abundance for all CUs in a given year was not a good predictor of whether those CUs were above their benchmarks in that year. In both cases, years with high aggregate abundance but with some CUs below their benchmark make a logistic model unsuitable for the purpose of estimating which aggregate abundance is linked to a high probability of each component CU being above its lower benchmark. Note that these regressions used the aggregate abundance of only the CUs used in the regressions, and excluded the other CUs. 

Several factors lead to these poor model fits. The Inside South Coast Chum SMU is made up of seven CUs that vary in their escapement abundance. George Strait and Howe Sound-Burrard Inlet have escapement in many years that are greater than the other CUs by two orders of magnitude. In addition, the correlation in escapement among these seven CUs is low. These characteristics mean that the aggregate abundance may be high due to one or more CUs with high escapements, while one more smaller CUs are below their benchmark. High aggregate escapements do not mean that all CUs are above their benchmark. This makes sense because:

- Large geographical range of SMU / component CUs
- Lots of different populations
- CUs have different numbers of populations (big differences), and those populations have big differences in abundance
- Differences in productivity among CUs/populations

**Summarize diagnostics (Bernoulli, p=0.9)**

Diagnostics for the logistic regressions are summarized below. *\textcolor{cyan}{LW: need input on how much detail to include here}*

Sgen:
(model fit for years up to brood year 2012)

```{r logistic-fit-diag-sgen}
# $DevResid
#  [1]  1.5103058  1.5833077 -0.7212199 -0.7244292 -0.7305280 -0.7151430 -0.7447297 -0.6833613 -0.7654111 -0.7401153  1.5121925
# [12] -0.7694616  1.5839014 -0.7016958  1.3841086  1.4475803 -0.8159303 -0.7228938 -0.7418517  1.5666292  1.5523207 -0.7096188
# [23]  1.5156620 -0.8178085  1.5483345 -0.7869247  1.5360388  1.3239095 -0.8653924  1.5699835  1.4895221 -0.7245176 -0.8886127
# [34] -0.8459808 -0.9165247 -0.8949060  1.4700380 -0.7625550 -0.7758330 -0.8371027  1.4745628 -0.7379357 -0.7742774 -1.0537538
# [45] -1.0825905 -1.0643677 -1.3576054 -0.8868636 -0.7852711 -1.0319873 -0.9150707 -1.0203902 -0.7895509  1.4557132 -1.2471559
# 
# $signTable
#   Param     Estimate   Std..Error   z.value    P.value
# 1   B_0 -1.515058578 0.7060392636 -2.145856 0.03188447
# 2   B_1  0.001002982 0.0009112125  1.100711 0.27102229
# 
# $p.PearChiSq
# [1] 0.453617
# 
# $p.DevChiSq
# [1] 0.1007752
# 

# $quasiR2
# [1] 0.0224255
# 
# $p.Wald
# [1] 0
# 
# $confMat
#        yHat
# y       FALSE
#   FALSE    38
#   TRUE     17
# 
# $hitRatio
# [1] 0.69

```

- Pearson residuals and deviance residuals - deviance residuals > 2?: No deviance residuals >2. 
- Trend in residuals over fitted values? Looking at postive and negative residuals separately, negative trend over fitted values /predicted proportions
- Autocorrelation of residuals?: No
- Statistical sigificance of model coefficients? B_0 p value =0.03. B_1 p value=0.27
- Pearson chi-squared stat: 0.45
- Deviance G-squared statistic
- quasi-Rsquared: 0.02. Ratio of fit to model is low.
- Wald test: Not sure how to interpret
- hit rate? 0.69

Percentile: 
(model fit for years up to return year 2018 - don't need recruits)

```{r logistic-fit-diag-perc}
# $DevResid
#  [1] -0.8406961 -0.8339881 -0.8488865 -0.8212552 -0.8740260 -0.8065754 -0.8281327  1.7147914 -0.8033258
# [10] -0.7654422 -0.8595049  1.8119211  1.7523104 -0.7698171 -0.8418346 -0.8271335 -0.7629487 -0.7529755
# [19] -0.8510790 -0.7236509 -0.7656350  1.6837794 -0.7878588 -0.7370794  1.8610516  1.7070509 -0.7534594
# [28]  1.7303123 -0.8373698  1.7300694 -0.7420715  1.7564968  1.7351794 -0.6988527 -0.8052713 -0.7957186
# [37] -0.7475578  1.7457886 -0.8250448 -0.7955161  1.8787431  1.9030854 -0.6069199 -0.4731779 -0.7131751
# [46] -0.7877844 -0.6244239 -0.6943669 -0.6310705 -0.7832699  1.7609352 -0.5188167 -0.5156067 -0.7100398
# [55] -0.6983311 -0.4115564 -0.7055435 -0.7507783
# 
# $signTable
#     Param     Estimate  Std..Error    z.value   P.value
# B_0   B_0 -0.626664955 0.830809130 -0.7542827 0.4506795
# B_1   B_1 -0.000784321 0.001193673 -0.6570652 0.5111390
# 
# $p.PearChiSq
# [1] 0.1290656
# 
# $p.DevChiSq
# [1] 0.1184212
# 
# $quasiR2
# [1] -0.07185179
# 
# $p.Wald
# [1] 0.97
# 
# $confMat
#        yHat
# y       FALSE
#   FALSE    44
#   TRUE     14
# 
# $hitRatio
# [1] 0.76
```

- Pearson residuals and deviance residuals - deviance residuals > 2?: Perason's residuals >2, deviance residuals up to 1.8
- Trend in residuals over fitted values? Looking at postive and negative residuals separately, negative trend over fitted values /predicted proportions
- Autocorrelation of residuals? No
- Statistical sigificance of model coefficients? B_0: 0.45, B_1: 0.51
- Pearson chi-squared stat: 0.13
- Deviance G-squared statistic: 
- quasi-Rsquared: -0.072 ; ratio of fit to model is low and ***negative?***
- Wald test: 0.97 ***Not sure how this is so high??***
- hit rate? 0.76  ***Not sure how this is so high??***



```{r chum-logistic-sgen, fig.cap="Logistic regression of whether escapement of all component CUs were above their $S_{gen}$ benchmarks based on aggregate abundance, for Inside South Coast Chum SMU. Includes the 5 CUs without CU-level infilling (no Bute Inlet or Upper Knight)", warning=FALSE, echo=FALSE, fig.align="center"}
download.file('https://github.com/Pacific-salmon-assess/SalmonLRP_RetroEval/raw/master/SCChumStudy/Figures/AnnualRetrospective/Bern.IndivRicker_NoSurv_noCUinfill_90/LogisticMod_2012.pdf', './figure/chum-logistic-sgen.pdf', mode="wb")
knitr::include_graphics(here::here('figure/chum-logistic-sgen.pdf'))
```

```{r chum-logistic-perc, fig.cap="Logistic regression of whether escapement of all component CUs were above their percentile benchmarks based on aggregate abundance, for Inside South Coast Chum SMU. Includes CUs where percentile benchmarks were appropriate (no Bute Inlet, Upper Knight, or Southern Coastal Streams)", warning=FALSE, echo=FALSE, fig.align="center"}
download.file('https://github.com/Pacific-salmon-assess/SalmonLRP_RetroEval/raw/master/SCChumStudy/Figures/AnnualRetrospective/Bern.Percentile_noCUinfill_90/LogisticMod_2018.pdf', './figure/chum-logistic-perc.pdf', mode="wb")
knitr::include_graphics(here::here('figure/chum-logistic-perc.pdf'))
```

### Comparison of LRPs based on Proportion of CUs above benchmark 


Retrospective analysis 
Can do this for 4 CUs with percentiles: 
plot status over time (aggregate abundance, with green/red for different methods)

We compared results of LRP status for percentile and decision tree methods, using different data sets (Table \@ref(tab:LRP-scenarios)). 



Comparing 

#### USING MULTIDIMENSIONAL APPROACH TO ASSESS CU STATUS

- Can do this for 4 CUs with percentiles/ 5 with Sgen (***? maybe, low alpha cutoff***): 
- plot status over time (aggregate abundance, with green/red for different methods)


## Discussion

### Suitabiliy of aggregate abundance LRPs

### Suitability of LRP based on status of component CUs (proportion)

### Assumptions and limitations

### Other sources of information to inform benchmarks

Indigenous Knowledge

- Two-Eyed Seeing - Etuaptmumk(Miâ€™kmaw) @reid_two-eyed_2020
- Historical baseline before records from western science @eckert_diving_2018, @lee_diverse_2019, @ban_incorporate_2018

Genetic tools and historical records

- Skeena sockeye @price_genetics_2019, @price_portfolio_2021
- Skeena chum @price_abundance_2013
- Cannery records @meengs_estimating_2005

Archaeological records

- BC herring @mckechnie_archaeological_2014

