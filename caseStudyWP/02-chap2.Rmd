---
output:
  pdf_document: default
  html_document: default
---
# LRP ESTIMATION METHODS

In this section, we provide an overview of methods used to develop LRPs for our three case studies. Detailed methods specific to each case study are provided in Sections 3 (Interior Fraser Coho), 4 (WCVI Chinook), and 5 (South Coast Chum, excluding Fraser). 

## OVERVIEW

- To ADD: LRPs under DFO's ..... can be based on abundance as well as other metrics (e.g., biological characteristics), and note option for trigger.  Note guidance from Ottawa that an LRP can be both a single value, or using the CU status approach. Will be brief here, but cite guidelines paper where this is better descried.  

We consider two different types of LRPs for Pacific salmon in our case studies:
1) Proportion-based LRPs, which are based on the proportion of CUs within an SMU that are assessed as being above 'poor' status, and
2) Aggregate abundance-based LRPs, which are based on total SMU-level spawning abundance 

While aggregate abundance-based LRPs are consistent with what is typically used for marine fish species (citation needed), proportion-based LRPs have been proposed for Pacific salmon to align with DFO's Wild Salmon Policy. As a default for our case studies, we assume that in order for an SMU to remain above its proportion-based LRP, 100% of CUs must have status estimates above poor. The LRP thus functions like a trigger that gets breached anytime one of more CUs within an SMU drops into the poor status zone.  In order ensure that aggregate abundance-based LRPs are also consistent with the WSP, we use two different approaches to identify aggregate abundance levels that have a high probability of all CUs being above poor status: (i) Logistic regression-based LRPs and (ii) Projection-based LRPs. More detailed descriptions of all of these methods are provided in the following sections, while guidance on when and how proportion-based and aggregate abundance-based LRPs should be applied is provided in Holt et al. (in review). We do not recommend that users apply any of the methods described in this case study paper without first consulting Holt et al. (in review).

The above definitions hinge on what defines 'poor' status. In the case of WSP Integrated Status Assessments, in which multiple metrics are combined to assign CU status, poor status corresponds with the 'red' status zone (citation needed). Metrics used to assign multidimensional CU status include absolute abundance relative to thresholds, relative abundance, short- and long-term trends in abundance, and distribution of abundance. While WSP Integrated status assessments are typically intensive expert-driven processes (e.g., ....), we demonstrate the application of a rapid multidimensional scanning tool in that is being developed by DFO's State of the Salmon Program to assess CU status under the WSP. In cases where up-to-date estimates of WSP integrated status or mutli-dimensional rapid status are not available, the delineation of poor CU status may be based on being below a single lower benchmark that has been identified as important for individual CUs by local experts. 

Under Canada’s WSP, a lower benchmark is defined as a level of abundance high enough to ensure there is a substantial buffer between it and any level of abundance that could lead to a CU being considered at risk of extinction; however in practice, some of the lower benchmarks applied line up exactly with COSEWIC's definition of 'endangered'. A variety of methods are available for estimating lower benchmarks depending on species and data availability (citations needed, but see Holt et al. 2009, Grant et al. 2011, Grant et al. 2020, Holt et al. 2018).  For example, if stock recruit data is available, as was the case for our IFCoho case study, Sgen may be used as a CU benchmark that defines 'poor' status, where Sgen is the number of spawners required to recover to $S_MSY$ (spawners maximum sustainable yield) within one generation under equilibrium conditions in the absence of fishing [@holtIndicatorsStatusBenchmarks2009]. In cases where there are no reliable stock-recruit data, estimates of Sgen may be based on habitat-area models (as per our WCVI Chinook Case Study). Or, alternatively, percentiles of historically observed escapement values may be used instead of Sgen (as per our ISC Chum case study). 

A more thorough discussion of available benchmarks, as well as how these relate to WSP Integrated Status Assessments, is provided in the companion working paper *Guidelines for Defining Limit Reference Points for Pacific Salmon Stock Management Units* (Holt et al. in review). 

<!-- To add back in:
Under Canada’s Wild Salmon Policy (WSP), the lower benchmark is defined as a level of abundance high enough to ensure there is a substantial buffer between it and any level of abundance that could lead to a CU being considered at risk of extinction, but in practice ....  We can provide a better description of the nuances here; it seems from talking to Carrie that for some benchmarks there is a buffer, but for others, there isn’t.
-->

<!--   

# The following text has been moved from below sections because it applied to all methods.  Work needed to better integrate it in.

Both proportion-based and aggregate abundance-based LRPs need the proportion of CUs that are required to be above their lower benchmarks to be specified.  We use a default requirement that 100% of CUs should be above lower benchmarks for our case study applications. Circumstances in which it may be appropriate to use a required proportion less than 100% are discussed in Holt et al. (in review; citation needed).

The first decision is about the 'required proportion of CUs that will be above their individual benchmarks'.  We use a default requirement that 100% of CUs should be above lower benchmarks for our case study applications of aggregate abundance-based LRPs. This requirement for 100% of CUs to be above their lower benchmarks is the same as that of the Proportion-based LRPs above. Circumstances in which it may be appropriate to use a required proportion less than 100% are discussed in Holt et al. (in review; citation needed). 

-->

## PROPORTION-BASED LRPS

A proportion-based LRP is simply the proportion of CUs required to be above CU-level lower benchmarks. For example, the LRP could be set at "100% of CUs with abundance > lower benchmark". In this case, the LRP would be breached anytime a single CU dropped below its lower benchmark. Guidance on how to select the required proportion, including when it may be appropriate to consider proportions < 100%, is provided in the companion working paper *Guidelines for Defining Limit Reference Points for Pacific Salmon Stock Management Units* (Holt et al. in review). We consider two types of proportion-based LRPs in our case studies. The first is based on the proportion of CUs with abundance above abundance-based lower benchmarks, while the second is based on the proportion of CUs for which a multidimensional synoptic status assessment indicates that status is in either the amber or green Wild Salmon Policy status zones.         

### Proportion of CUs above abundance-based lower benchmarks

For SMUs in which CU-level abundance relative to abundance-based lower benchmarks is assessed annually, LRPs can be set at the required proportion of CUs with abundance above their abundance-based lower benchmarks. 



### Proportion of CUs with multidimensional status above the red zone

<!-- Note from Sue:

For multi-dimensional status, we are using the term ‘lower benchmark’ to be Red status zone for the CU. Not entirely a correct usage of this term, but applies it to the language used for LRP triggers of rebuilding plans.

-->


Canada's Policy for Conservation of Wild Pacific Salmon (Wild Salmon Policy, WSP) sets out requirements for the assessment of status of salmon CUs (@canada_canadas_2005). Peer-reviewed, integrated status assessments require large amounts of time and work. The State of the Salmon program (Fisheries and Oceans Canada) is developing a method of assessing the status of CUs more rapidly (@pestalAlgorithmsRapidStatus2021, in prep). Using the inputs and outcomes of status assessments for Fraser River sockeye, Interior Fraser coho, and Southern BC Chinook (@dfoWildSalmonPolicy2015, @dfoIntegratedBiologicalStatus2016, @dfo2017FraserSockeye2018,  @grant2017FraserSockeye2020), this method uses Classification and Regression Tree (CART) analyses to create algorithms that approximate the status of the integrated assessments. Essentially, it uses a decision tree to evaluate status based on data type, quality, abundance, and trends to assign a status to CUs (e.g., Figure \@ref(fig:decision-tree)). An expert review of these statuses is an intentional part of the process. When using this method in the case study, we took the outputs of the algorithms at face value and did not confirm using expert opinion. 


```{r decision-tree, fig.cap="Decision tree to assess status of Conservation Units based on the Wild Salmon Policy, under development by State of the Salmon Program", warning=FALSE, echo=FALSE, fig.align="center"}
source("R/make_tree_diagram.R")
knitr::include_graphics("figure/decision_tree.png")
```


## AGGREGATE ABUNDANCE-BASED LRPS

Aggregate abundance-based LRPs represent the SMU-level abundance at which there is a sufficiently high probability that 100% of CUs will be above their individual benchmarks. This definition requires a decision to be made about what represents a 'sufficiently high probability' that 100% of CUs will be above their benchmarks. We consider four alternative probability levels for our case studies that represent a range of calibrated probability categories developed by the Intergovernmental Panel on Climate Change [@frame_guidance_2010]: 50%, 66%, 90%, and 99%. The 50% value represents the mid-point of the "About as likely as not" category (33 - 66%), indicating that there is an equal probability that all CUs will be above their LBMs as there is that they will not. The 66% values represents the lower end of the "Likely" category (i.e., it is "Likely" that all CUs will be above their LBMs), the 90% value represents the lower end of the "Very Likely" category, and the 99% value represents the "Virtually Certain" category. A discussion of considerations for selecting the appropriate probability threshold when calculating abundance-based LRPs is included in the working paper *Guidelines for Defining Limit Reference Points for Pacific Salmon Stock Management Units* (Holt et al. in review).  For our case studies, we focus on a 50% probability threshold for sensitivity analyses, but show sensitivity to other values.  
 
We consider two types of aggregate abundance-based LRPs in our case studies: Logistic regression LRPs and Projected LRPs.  Logistic regression LRPs are based on historical data, and thus represent conditions that have been previously experienced by a SMU. In comparison, projected LRPs use historical data as a basis for quantifying population dynamics, but are based on projections of future states, and thus, allow uncertainty in future processes to be accounted for through alternative scenarios.  

### Logistic regression-based LRPs{#logisticMethods}

Logistic regression-based LRPs (also called Logistic regression LRPs) are derived from an empirically estimated relationship between CU-level status and aggregate SMU abundance. Using this approach, the LRP represents the aggregate abundance that has historically been associated with a pre-specified probability of a required proportion of CUs being above their lower benchmarks. In all three case studies, we assume that all CUs are required to be above their lower benchmarks (i.e., proportion = 100%). For each year of observed data, CU-level status is quantified as a Bernoulli variable: 1 (success) = all CUs have spawner abundance greater than their lower benchmark, $S_i > LBM_i$, and 0 (failure) = all CUs did not have $S_i > LBM_i$. A logistic regression is then fit to predict the probability that all CUs will have $S_i > LBM_i$ as a function of aggregate spawner abundance to the SMU using the logistic regression equation:

\begin{equation}
  \log(\frac{p}{1-p}) = B_0 + B_1 \sum_{i}^{i=nCUs} S_{i,t}
   (\#eq:logistic)
\end{equation}

where, $p$ is probability, $B_0$ and $B_1$ are estimated logistic regression parameters and $S_{i,t}$ is spawner abundance to CU $i$ in year $t$. Equation \@ref(eq:logistic) is then re-arranged calculate the LRP as the aggregate spawner abundance associated with the pre-specified probability threshold of $p^*$,

\begin{equation}
  LRP = \frac{log(\frac{p^*}{1-p^*}) - B_0}{B_1}
  (\#eq:logisticLRP)
\end{equation}

An example logistic regression fit is shown in Figure\@ref(fig:example-logisticFit). We show the estimation of LRPs based on this fit for four possible probability thresholds: $p^*$ = 0.5, 0.66, 0.90, and 0.99. For each $p^*$ level, LRP estimates represent the aggregate abundance that is associated with that probability of all CUs having $S_i > LBM_i$. 


```{r example-logisticFit, fig.cap="Logistic regression fit to annual Bernoulli data to predict the probability of all CUs being above their lower benchmark (LBM) as a function of aggregate SMU abundance. Black dots are annual Bernoulli indicators showing whether the requirement of all CUs above their LBM was met (success = 1) or not (failure = 0) in each year, the black solid line in the maximum likelihood model fit to indicator data, and the grey shaded region shows the the 95-percent confidence interval around the fit model. Coloured lines demonstrate how aggregate abundance LRPs are calculated for 4 different probability thresholds: p* = 0.5 (yellow), 0.66 (blue), 0.90 (green), and 0.99 (orange) probability that all CUs > LBM. Horizontal dotted lines intersect the y-axis at each probability threshold, while the solid vertical lines show the corresponding aggregate escapement that will represent the LRP.", out.width = '60%', warning=FALSE, echo=FALSE, fig.align="center"}
knitr::include_graphics("figure/methods-Example-LogisticLRP.png")
```

We initially considered an alternative approach to logistic regression in which the LRP represents the aggregate abundance that has historically been associated with a pre-specified *proportion* of CUs being above their lower benchmark ($S_i > LBM_i$, where i = a CU). Using this approach, CU-level status was quantified as the number or CUs with $S_i > LBM_i$ for each year of observed data.  A logistic regression was then fit to predict the proportion of CUs with $S_i > LBM_i$ as a function of aggregate spawner abundance to the SMU (i.e., abundance from nCUs combined). We do not show present this method for our case studies however due to inherent limitations when the required proportion of CUs above their lower benchmarks is 100%. Equation \@ref(eq:logisticLRP) cannot be solved directly for a threshold proportion of $p^*$ = 100%, and LRP estimates were highly sensitive to the choice of $p^*$ value used as a proxy. Using $p^*$ = 99% vs. $p^*$ = 99.9% vs. $p^*$ = 99.99% gave very different LRP estimates. 



To Do: mention uncertainty


##### Logistic Regression Model Diagnostics

There are several assumptions associated with logistic regression, of which four are relevant for our application to LRPs, listed below. Model diagnostics were applied to evaluate the extent to which those assumptions were met, as well as statistical significance of model coefficients, goodness-of-fit, and classification accuracy of LRPs developed from the logistic regression. All analyses were implemented using R v.4.0.4 unless otherwise specified [@r_core_team_r_2021].

1. The relationship between aggregate abundance and log-odds (the logarithm of the odds of all CUs being above their lower benchmark) is linear.

2. The observations are independent of each other (i.e., residuals are not autocorrelated).

3. There are no influential outliers. 

4. The sample size is large. Logistic regression assumes that the sample size of the data set is large enough to draw valid conclusions from the fitted model.


**Evaluating assumption of linearity (Assumption 1)**

A Box-Tidwell test was used to evaluate linearity by assessing the significance of an additional interaction term in the logistic regression, 

\begin{equation}
  \log(\frac{p}{1-p}) = B_0 + B_1 \sum_{i}^{i=nCUs} S_{i,t} + B_2 \sum_{i}^{i=nCUs} S_{i,t} \times \log (\sum_{i}^{i=nCUs} S_{i,t})
   (\#eq:BoxTidwelllogistic)
\end{equation}

A significant interaction term $B_2$, indicates a non-linear relationship between aggregate abundance and log-odds, violating this assumption [@fox_applied_2016].


**Evaluating independence (Assumption 2)**

Deviance residuals, $d$, were estimated for each year,

\begin{equation}
   d = \pm \sqrt { -2 ( y \log(\frac{\mu}{y}) + (1-y)\log(\frac{1-\mu}{1-y}) ) }
   (\#eq:DevianceResid)
\end{equation}

where $\mu$ is the predicted probability of all CUs being above their lower benchmark and $y$ is the observation (1 or 0, indicating all CUs above or not, respectively), in a given year [@fox_applied_2016]. Equation \@ref(eq:DevianceResid) reduces to,

\begin{equation}
   d =  - \sqrt { -2 \log(1-\mu) }
   (\#eq:DevianceResidy0)
\end{equation}

when $y=0$, and to,

\begin{equation}
   d =  \sqrt { -2 \log(\mu)  }
   (\#eq:DevianceResidy1)
\end{equation}

when $y=1$ [@ahmad_diagnostic_2011].


The magnitude of lag-1 autocorrelation was then estimated among deviance residuals and evaluated for statistical significance. 


**Evaluating outliers (Assumption 3)**

As a general rule of thumb, deviance residuals greater than 2 are considered to be to be outliers, since 95\% of the distribution is expected to be within 2 standard deviations of the mean. Further identifying influential outliers is recommended, but was not feasible for this application because TMB, the software used to estimate model parameters, does not provide the hat-matrix required to assess influence of individual points.


**Evaluating sample size (Assumption 4)**

A minimum of 10 data points for the least frequent outcome is recommended to avoid biases in model coefficients [@peduzzi_simulation_1996]. For example, if the frequency of outcomes were 0.5 and 0.5 (for 0 and 1, respectively), then a sample size of at least 10/0.5 = 20 would be sufficient, and this minimum sample size would be higher if the data were skewed, e.g., if frequency of outcomes were 0.7 and 0.3, the minimum sample size would be 10/0.3 = 33. Although it is possible to estimate LRPs with lower sample sizes, the risks of biases in model parameters increases.


**Statistical significance of model coefficients**

Statistical significance of coefficients was evaluated using the Wald test statistic, calculated from the ratio of the model coefficient to the standard error of that coefficient, which is assumed to be normally distributed. Test statistics and significance were estimated within TMB [@kristensen_tmb_2016]. <!-- Not needed: P-values <0.05 indicate that the null hypothesis of the coefficient being equalt to 0 is rejected [@fox_applied_2016].-->


**Goodness-of-fit**

The goodness-of-fit was evaluated by comparing the ratio of residual deviance to null deviance (similar to a likelihood ratio). This ratio is assumed to follow a Chi-square distribution with 1 degree of freedom, the difference in the number of parameters between full and null models. P-values <0.05 indicate significant lack of fit [@fox_applied_2016].

In addition, the quasi-$R^2$ was calculated to indicate the ratio of the model fit to the null model without an independent variable, 

\begin{equation}
   quasi-R^2 =  1- \frac{\sum_{t}^{t=nYears} d} {\sum_{t}^{t=nYears} d_0} 
   (\#eq:quasiR2)
\end{equation}

where $d_0$ are the deviance residuals for the null model. The quasi-$R^2$ is a measure of the strength of the relationship between aggregate abundances and probability of all CUs being above their lower benchmarks, but unlike $R^2$ values for linear models, it does not represent the percentage of variance explained by the model and is not related to the correlation coefficient.


**Classification accuracy of LRPs**

Classification accuracy was evaluated based on the ratio of successful classifications to total number of data points in the logistic regression, also called the hit ratio. Successful classifications were the number of years when the model successfully predicted that all CUs were above their lower benchmark plus the number years when the model successfully predicted that at least one CU was below its lower benchmark.  The hit ratio tends to be biased towards unrealistically good classification rates when computed with the same sample used for fitting the logistic model. Therefore, we also considered an out-of-sample approach to classification accuracy, where the logistic regression was estimated iteratively removing a single data point and the occurrence of successes relative to observations were based on the model that did not contain that data point. 



### PROJECTION-BASED LRPS

Projected LRPs are estimated using stochastic projections of future CU abundances to characterize the relationship between aggregate SMU-level spawner abundance and the probability that the required proportion of CUs will be above their lower benchmarks (e.g. Sgen). We used the samSim modelling tool to conduct stochastic projections for our case study applications. samSim is an R package that was developed to quantify recovery potential for Pacific salmon populations (Holt et al. 2020; Freshwater et al. 2020). We created a modified version of samSim to support LRP estimation. The LRP version of samSim is described in detail in Appendix  \@ref(app:samsim-appendix), while model code is available on GitHub at: https://github.com/Pacific-salmon-assess/samSim/tree/LRP.  


Updated functionality for the LRP version of samSim include:
<!-- KH comment: Not sure if these updates are neccessary here ... this text could be moved to the appendix? - or, just put in the github readme for the LRP branch of samSim?? -->

* The option to sample stock recruitment parameter sets directly from an estimated Bayesian joint posterior distribution.

* The addition of a stock recruitment function that includes an environmental co-variate, as well as specification of future variability in the environmental co-variate (required for Interior Fraser Coho case study).

* The option to initialize population dynamics for individual CUs at unfished equilibrium when no historical recruitment data are available. While this option would not be appropriate for projections aimed at estimating recovery from a current state, it can be used to estimate projection-based LRPs because we are only interested in the underlying relationship between aggregate abundance and the probability individual CUs will be above their lower benchmark.

* The option to include a log-normal bias-correction factor of $-\sigma^2 / 2$ to recruitment projected using one of the two available Ricker stock recruit models. This option was added to accommodate cases in which samSim is parameterized using stock recruitment parameters that have been corrected for log-normal bias to represent expected (mean) parameters. The log-nomral bias correction is commonly applied in stock recruit modelling because the expected value of *e*^$\sigma$ is *e*^$\sigma^2 / 2$} rather than zero when recruitment deviations are normally distributed (Cox et al. 2011, 2019a, 2019b; Grandin and Forrest 2017; Ohlberger et al. 2019; Olmos et al. 2019; Forrest et al. 2020, Weir et al., in press). When input parameters have been corrected for this log-normal bias, the bias correction must also be added to projections.

* Specification of variability in exploitation rates as a function of both variability among years and variability among CUs.

Detailed descriptions of the parameterization of samSim for our two case study applications of abundance-based projected LRPs (Interior Fraser Coho and WCVI Chinook) are presented in Chapters 3 and 4, respectively. In both cases, we incorporated uncertainty into projected CU dynamics through the specification of empirically-derived probability distributions for key biological and management parameters, including stock-recruitment parameters, age-at-maturity, and exploitation rates (ER). Larger structural uncertainties in model formulation were represented through the use of sensitivity analyses and/or alternative operating models (OMs). Observation error was not included in projections because derivation of LRPs was based on projected 'true' abundance levels rather than observed abundance. Furthermore, we were only applying a simple fixed ER harvest strategy when projecting forward, so annual variability arising from observation error would be accounted for by our specification of between-year variability in ERs.  

The following steps were taken to calculate projected LRPs using samSim:

   1. Use samSim to project spawner abundances forward for $nYears$ over $nTrial$ stochastic simulations.


   2. For each simulated year-trial combination, characterize abundances as follows:

      * Assign aggregate SMU level spawner abundance for each year-trial combination to an abundance bin ($AggS_{bin}$), based on intervals of 200 fish . E.g., $AggS_{bin}$ = 0:200 fish, 200:400 fish, 400:600 fish, ... etc.

      * Determine whether all CUs for that year-trial combination were above their CU-level lower benchmarks. If they were, the year-trial combination is scored as a success (1). If they were not, the year-trial combination is scored as a failure (0).


   3. For each aggregate abundance bin, $AggS_{bin}$:

      * Summarize the realized number of year-trial combinations that fell within that bin. For example, if a projection was run for 30 years with 1000 replicates, there might be 200 year-trial combinations that had a aggregate abundance in 10,000 - 12,000 fish bin.
      <!-- CW: Need to check these, It says that fish bins are 200 fish, but example uses 2000 fish bin -->

      * Summarize the number of 'successful' year-trial combinations that occurred for that bin. For example, 50 of 200 year-trial combinations in the aggregate abundance bin of 10,000 - 12,000 fish are successes in which all CUs were above their lower benchmarks.

      * Calculate the probability that all CUs will be above their lower benchmarks for that bin as:
\begin{equation}
   Pr(All CUs > LBM) = \frac{Number of success in SAgg_{bin}} {Number of realizations in SAgg_{bin}}
   (\#eq:projBins)
\end{equation}
For example, if 50 of the 200 realizations that fell within the $SAgg_{bin}$ of 10,000 - 12,000 fish were 'successes', there would be a 25% probability (50 / 200 = 0.25) that all CUs would be above their lower benchmarks when aggregate abundances are between 10,000 and 12,000 fish.

   4. Identify the LRP as the aggregate abundance bin, $AggS_{bin}$, that is closest to the required probability threshold that all CUs are above their LBMs.


An example of the derivation of an LRP from the projected curve of aggregate abundance bins versus the probability of all CUs being > their lower benchmark is shows in Figure @ref(fig:example-projectedCurve) for the four probability levels used in our case studies (p = 0.5, 0.66, 0.90, and 0.99). Uncertainty estimates for LRPs are not available based on this method, but that LRP estimates should be presented as a range based on the $SAgg_{bin}$ bin size.



```{r example-projectedCurve, fig.cap="Example of projected probability curve derived from projections over 30 years and 10,000 MC trials.  The curve shows the projected probability of all CUs being above their lower benchmark (LBM) as a function of aggregate SMU abundance, with each dot in teh curve representing a single combination of year and simulation replicate. Coloured lines demonstrate how aggregate abundance LRPs are calculated for 4 different probability thresholds: p* = 0.5 (yellow), 0.66 (blue), 0.90 (green), and 0.99 (orange) probability that all CUs are greater than their LBM. Horizontal dotted lines intersect the y-axis at each probability threshold, while the solid vertical lines show the corresponding aggregate escapement that will represent the LRP.", out.width = '60%', warning=FALSE, echo=FALSE, fig.align="center"}
knitr::include_graphics("figure/methods-Example-ProjectedLRP.png")
```



