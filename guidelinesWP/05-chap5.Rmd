# Recommendations for Future Work {#recommendations}

Should highlight the identification of questions / outstanding guidance that were beyond our scope


<!--from CS paper-->
We found that removing component CUs from assessments of an SMU tended to increase variability in SMU-level status, which may be more pessimistic or optimistic than when all CUs are considered depending in part on the level of covariation among CUs. <!--CH: I suggest we broaden this pgh to refer to both ppn-based and aggregate-abudnance based LRPs. Kendra shows this point best for logistic-regression based LRPs, but not ppn-based LRPs. While Luke shows variability in whether LRP is breached among data sets, that section does not show variability in status (% of CUs above red) per se, like Kendra does. And I don't show it at all for WCVI CK--> If the LRP of 100% of CUs above red status has been breached for an SMU, the inclusion of additional CUs may further deplete or improve status (% of CUs above red), but will not increase status to above the LRP (100%). In contrast, if the LRP is not breached for an SMU, then the inclusion of additional CUs may deplete status to below the LRP or keep status at 100% of CUs above red zone. This asymmetrical impact of increased monitoring of CUs on SMU status may reduce incentives to extend monitoring to data-deficient CUs.<!--CH: Note to add this to Guidelines paper. This asymmetric property of both ppn-based and to a lesser extent these aggregate-abundance based LRPs is a characteristic we should highlight and cautious about; is a result of LRPs considering dynamics of component stocks that vary independently. -->


- Specific questions about how well index sites within a CU represent the CU as a whole (i.e., representativeness question, but for sites within a CU instead of CUs within an SMU)

- Consideration of additional habitat-based benchmarks

- Suggestion to consider all three management levers in LRP development: harvest, hatcheries and habitat. Should LRPs be identified along those three dimensions and/or integrate information for those 3 levers?

- Standard versus hierarchical stock-recruitment models for estimating benchmarks


- We found that the projecton-based LRP values were dependant on the long term exploitation rate average. Higher values of exploitation rates resulted in higher abundance LRPs. Future research could use this feature of the projection tool to identify the harvest rates that would result in aggregate LRP values that are lower than the past observed aggregate abundances. 


When applying methods to specific case studies, we recommend that aggregate-abundance based LRPs consider major structural uncertainties either through sensitivity analyses or model ensemble approaches. These analyses can answer the questions, how sensitive are aggregate-abundance based benchmarks to key model uncertainties, including those related to time-varying parameters, observation errors, and covariance in population dynamics and vulnerability to harvest. In addition, we recommend simulation evaluation be used to assess the robustness of LRPs to violating assumptions given underlying known statuses. Simulation evaluation could further be used to assess the frequency of updates to LRPs required to achieve objectives given underlying changes in model parameters and structure. <!--CH: observation errors in CU-status are relevant for logistic-regression LRPs as they might inflate noise in the LR, and they are relevant to the projection-based LRPs in the noise in the spawner and recruitment data-->



<!--

CW: I moved this here from ch 4.

- Question: could serious harm may mean extinction rather that in the red zone?  

- The question of whether a CU within a larger SMU can persist in the red zone is something that could be simulation tested; although, this would require harvest control rules to be specified for testing.  Such an approach would be case-specific and outside of the scope of our work.  However, we could consider recommending that if a decision is made for a CU to allow some proportion of CUs to be in the red zone, quantitative evaluation (e.g., simulation testing) should be used to demonstrate that red CUs will not be lost. [Although, we may still want to consider putting some bounds on what proportion would be allowed to be below their lower benchmark, i.e., a large proportion of CUs persisting in the red zone may not be acceptable ].

-if using $<$100 $\%$ of CUs $>$ red, could recommend simulation testing



Beyond scope: CU-level benchmark considerations
- How do data availability and biological considerations interact to inform a decision about which CU-level benchmark to use? (e.g, Sgen from SSR vs. Sgen from Watershed-Area vs. percentile vs. distributional benchmarks, etc)?  
- Under what conditions should Watershed-Area based LRPs be used? 
- How do mean and distributions (uncertainties) of watershed-area based and stock-recruitment based benchmarks compare?
- Under which levels of data uncertainties do stock-recruitment based LRPs outperform habitat-based LRPs? 
- In cases where watershed-area based benchmarks and stock-recruitment based benchmarks are available, both should be presented and used to derive complementary LRPs to capture our underlying model uncertainties.
- Alternatively, could be combined by using watershed area to inform prior on beta in the stock-recruitment model
- What if stocks have different levels of data, e.g., Fraser Sockeye, where stock-recruitment as available for some CUs, while others have only escapement data.  When is it beneficial to use available data for data poor CUs vs when to exclude them?

## Incorporating uncertainty in aggregate abundance LRP estimation

- How should uncertainty in benchmarks be incorporated in the LRP if different methods are used to estimate CU-level status within an SMU (i.e., some CUs have stock-recruitment benchmarks, while others rely on percentile-based or habitat-based benchmarks). Bootstrapping from uncertainties in CU-level benchmarks could be considered in these cases. Although, simulation testing of these scenarios may be outside the scope of this paper, guidance based on best-practices from the literature could be provided.

-->


## Time-varying parameters and impacts on LRPs

There is increasing evidence of time varying parameters in Pacific salmon populations, particularly relating to declines in productivity [e.g., @holtImpactTimevaryingProductivity2020,  @dornerSpatialTemporalPatterns2018, @malickRegionalScaleDeclinesProductivity2016, @petermanWidespreadDecreaseProductivity2012]. In Canada, DFO assessments identified declines in productivity for various CUs, e.g., Fraser sockeye [@grantEvaluationUncertaintyFraser2011, @grantIntegratedBiologicalStatus2013, @huangRecoveryPotentialAssessment2021], Southern BC Chinook (cite SAR 2016/042), Fraser Chinook (Cite RPA)  and Interior Fraser Coho [@arbeiderInteriorFraserCoho2020]. These assessments relied on a variety of tools to identify trends in productivity including the evaluation of trends in log spawners per recruit [@arbeiderInteriorFraserCoho2020], evaluation of trends in residuals from recruitment curve fits [@grantEvaluationUncertaintyFraser2011], and explicit consideration of time-varying parameters when fitting recruitment curves using Kalman filter or recursive Bayes approach [huangRecoveryPotentialAssessment2021 and RPA]. 

Time-varying recruitment parameters affect estimates for salmon benchmarks (e.g., $S_{MSY}$ and $S_{gen}$) [@holtEvaluatingBenchmarksPopulation2011] and are also likely to affect population trends, resulting in changes to benchmarks based on historical observations (e.g., percentile-based benchmarks) [@holtEvaluatingBenchmarksBiological2018]. Analytical methods for time-varying reference points have been also proposed for other marine fish species [@amarEvaluationTwoManagement2009; @puntFisheriesManagementClimate2014], some of which have been evaluated empirically and in simulation with mixed results [@olearyComparisonMultipleApproaches2020; @bergerCharacterTemporalVariability2019]. For Pacific salmon, time-varying benchmarks effects will have an impact on the classification of CUs status. However determining support for time-varying parameters is not always straightforward. Common statistical diagnosis such as inspection of residuals and use of information criteria (e.g. AIC and BIC) often produce conflicting results [@holtImpactTimevaryingProductivity2020]. A review of stock-recruit analyses for Pacific salmon, including the use of environmental covariates and time-varying parameters, highlighted that even when there is strong evidence for non-stationarity in salmon populations, it is not clear if reference points should be adjusted accordingly [@adkisonReviewSalmonSpawnerRecruitment2021].<!--CH addition next sentence--> Where stock depletion is associated with time-varying parameters that are thought be reversible, it may be more appropriate to protect the population from harvest by maintaining high reference points using historical data [@dfoProceedingsNationalWorkshop2013; @szuwalskiClimateChangeNonstationary2016]

Time-varying stock-recruitment dynamics usually occur at the CU level, and the implications for SMU-based LRPs are not straightforward. There are no clear guidelines on how to translate time-varying stock recruitment parameters into reference points. Effects of time-varying CU recruitment dynamics on aggregate-abundance and proportion-based LRPs will depend on the degree of synchrony among CUs, the direction of the change in recruitment parameters, past and current stock status, among other factors. For example, in our case study on Interior Fraser River Coho Salmon, when consistent reductions in productivity was introduced in one sensitivity analysis (analysis that included informative priors on capacity in CU-level spawner-recruitment models), benchmarks declined for most CUs as did aggregate-abundance based LRP for the SMU. However, in cases where productivity varies at different rates among CUs or capacity changes as well, impacts on CU-level benchmarks and SMU-level LRPs will not be easily predictable. When evaluating the impacts of productivity changes on reference points, @bergerCharacterTemporalVariability2019 suggests that dynamic reference points are most useful in situations when stock productivity shifts directionally and the productivity signal is correctly ascertained. In contrast, uncertainty from incorrectly identifying productivity trends can be a major source of innacuracy in stock status [@bergerCharacterTemporalVariability2019]. In addition, even if time-varying benchmarks and their associated effects on LRPs are considered, it is difficult to define how often LRPs should be changed [@zhangReportOceanFrontier2021]. Mistimed changes in benchmarks or LRPs may lead to bias in stock status [@holtImpactTimevaryingProductivity2020] and volatility of management responses may lead to management uncertainty, reducing trust in the management process [@adkisonReviewSalmonSpawnerRecruitment2021]. 



The Precautionary approach policy recommends that changes to the reference points should only be adjusted when there is considerable evidence that productivity has changed and there are no expectations that these changes will be reverted naturally or achieved through management [@dfoHarvestStrategyCompliant2006]. Klaer et al 2015 devised a framework for evaluation the degree of confidence in productivity shifts in Australian fisheries, similar approaches could be adapted for Canadian Salmon populations. Recent studies recommend the use of case specific feedback simulation exercises in order to determine the appropriate scale to adjust reference points when stock-recruitment parameters are non-stationary [@holtImpactTimevaryingProductivity2020; @zhangAccountingNonstationaryStock2021; @olearyComparisonMultipleApproaches2020]. However, full feedback simulation studies might not be feasible for every conservation unit due to limited resources. Future research should focus on identifying general advice on the best practices for adjusting benchmarks when the stock dynamics is thought to be non-stationary.   

 

<!--

old notes on time-varying parameters
- Briefly document evidence for time-varying productivity for Pacific salmon
- Summarizing recent DFO CSAS documents that include discussion of time-varying reference points for Pacific salmon, and recent primary publications:
- Summarize approach for considering time-varying productivity in WSP CU assessments (e.g., Kalman filter on productivity parameters))

@adkisonReviewSalmonSpawnerRecruitment2021 reviews stock recruitment analysis for Pacific salmon, including the use of environmental covariates and time-varying parameters. They highlight that even though there might be strong evidence for non stationarity in salmon populations, it is not clear if reference points should me adjusted accordingly. 

@kronlundConsiderationsDesignRebuilding2021 recommends that any decision to introduce time-varying reference points be based on evidence supporting that rebuilding could reasonably be expected. They recommend the use of feedback simulations to illustrate the consequences of time-varying benchmarks and identify exceptional circumstances that should lead to re-examination of reference point and management measures. 

 @zhangAccountingNonstationaryStock2021 illustrates the effects of time-varying recruitment parameters on MSY-based reference points for iteroparous fish stocks (cod and plaice). They highlight that more precautionary benchmarks are necessary to account for the parameter uncertainty in highly dynamic ecosystems. However, they observed that effects on reference points depend on the magnitude and structure of the stochasticity in stock-recruitment relationships, therefore they recommend case specific simulation studies be performed to identify explicit impacts on MSY-based reference points.

-->